{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CapArrow/HighCountingVQA/blob/main/create_dataset_json.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbCbS0imJVZY"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import requests\n",
        "import os\n",
        "import zipfile\n",
        "import json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "from imutils import paths\n",
        "from tabulate import tabulate\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cB2kvu2Ji3l",
        "outputId": "316a4286-d2c3-43d8-a401-e1cc17e41313"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# mount Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6DfvEalJrXW",
        "outputId": "0d756f2e-b53d-40a7-a2bd-9fc4b92a168e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1LQRkg9gduygZjO84k_knGQGpy1qEPTp6/Colab Notebooks\n"
          ]
        }
      ],
      "source": [
        "# change directory to the Colab Notebooks folder with link to drive of lars\n",
        "%cd /content/drive/My Drive/MMDL2024/Colab Notebooks/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53aJD8UWJs_m",
        "outputId": "c6d9487d-361a-4934-e6f4-61e1aab0a63b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['image', 'answer', 'data_source', 'question', 'image_id', 'question_id'])\n",
            "dict_keys(['image', 'answer', 'data_source', 'question', 'image_id', 'question_id', 'issimple'])\n"
          ]
        }
      ],
      "source": [
        "# load json\n",
        "train_file = open(\"tallyqa_train.json\")\n",
        "test_file = open(\"tallyqa_test.json\")\n",
        "train_data = np.array(json.load(train_file))\n",
        "test_data = np.array(json.load(test_file))\n",
        "train_file.close()\n",
        "test_file.close()\n",
        "\n",
        "# test file has one additional key: \"issimple\"\n",
        "# in the following this key is ignored\n",
        "print(train_data[0].keys())\n",
        "print(test_data[0].keys())\n",
        "\n",
        "\n",
        "# concatenate data\n",
        "data_dict = np.concatenate((train_data, test_data), axis=0)\n",
        "# get dict keys\n",
        "data_keys = data_dict[0].keys()\n",
        "# transform dicts to list and get data array\n",
        "df = pd.json_normalize(data_dict)\n",
        "data = df.to_numpy()[:, :6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHqcXy6uKv5s",
        "outputId": "58018002-a298-485d-8c74-15dd8f6f0c6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------  ------\n",
            "questions  287907\n",
            "images     159432\n",
            "---------  ------\n",
            "----------  -----\n",
            "coco_train  66943\n",
            "coco_val    32633\n",
            "vg_100      35270\n",
            "vg_100_2    24586\n",
            "unknown         0\n",
            "----------  -----\n"
          ]
        }
      ],
      "source": [
        "def file_split_by_name(data):\n",
        "  coco_train = []\n",
        "  coco_val = []\n",
        "  vg_100 = []\n",
        "  vg_100_2 = []\n",
        "  unknown = []\n",
        "  for fname in data:\n",
        "    foldern, imagen = fname.split(\"/\")\n",
        "    if foldern == \"train2014\":\n",
        "      coco_train.append(fname)\n",
        "    elif foldern == \"val2014\":\n",
        "      coco_val.append(fname)\n",
        "    elif foldern == \"VG_100K\":\n",
        "      vg_100.append(fname)\n",
        "    elif foldern == \"VG_100K_2\":\n",
        "      vg_100_2.append(fname)\n",
        "    else:\n",
        "      unknown.append(fname)\n",
        "\n",
        "  table = [[\"coco_train\", len(coco_train)], [\"coco_val\", len(coco_val)], [\"vg_100\", len(vg_100)], [\"vg_100_2\", len(vg_100_2)], [\"unknown\", len(unknown)]]\n",
        "  print(tabulate(table))\n",
        "  return coco_train, coco_val, vg_100, vg_100_2\n",
        "\n",
        "# extract all relevant image_names from data\n",
        "data_image_names = np.unique(data[:, 0])\n",
        "np.random.shuffle(data_image_names)\n",
        "print(tabulate([[\"questions\", len(data)], [\"images\", len(data_image_names)]]))\n",
        "# get all images names wrt. the datasets which are used in tallyqa\n",
        "coco_train_files, coco_val_files, vg_100k_files, vg_100k_2_files = file_split_by_name(data_image_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bi0f1zMnNlA5",
        "outputId": "87a4ba24-ac1b-4746-f561-a7cc76abb0db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Images found in drive: \n",
            "----------  -----\n",
            "coco_train  82783\n",
            "coco_val    40504\n",
            "vg_100      64346\n",
            "vg_100_2        0\n",
            "----------  -----\n"
          ]
        }
      ],
      "source": [
        "train2014 = len(list(paths.list_files(\"coco/train2014/\")))\n",
        "val2014 = len(list(paths.list_files(\"coco/val2014/val2014/\")))\n",
        "vg_100k = len(list(paths.list_files(\"visual_genome/VG_100K/\")))\n",
        "vg_100k_2 = len(list(paths.list_files(\"visual_genome/VG_100K_2\")))\n",
        "table = [[\"coco_train\", train2014], [\"coco_val\", val2014], [\"vg_100\", vg_100k], [\"vg_100_2\", vg_100k_2]]\n",
        "print(\"Images found in drive: \")\n",
        "print(tabulate(table))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGiUXf2Fbqhl"
      },
      "outputs": [],
      "source": [
        "# extract every question with answer greater then 4\n",
        "np.random.seed(9929395)\n",
        "gcd = data[:, 1] >= 4\n",
        "greater_count_data = data[gcd]\n",
        "lesser_count_data = data[np.logical_not(gcd)]\n",
        "np.random.shuffle(lesser_count_data)\n",
        "# create new data array with all answers greater then 4 and 20.000 answers lower then 4\n",
        "new_data = np.concatenate((greater_count_data, lesser_count_data[:20000]), axis=0)\n",
        "# train, val, test split (60, 20, 20)\n",
        "np.random.shuffle(new_data)\n",
        "max_len = len(new_data)\n",
        "b1 = int(max_len * 0.6)\n",
        "b2 = int(max_len * 0.8)\n",
        "new_train_data = new_data[:b1]\n",
        "new_val_data = new_data[b1:b2]\n",
        "new_test_data = new_data[b2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rmtQ55QykNgI"
      },
      "outputs": [],
      "source": [
        "def create_json(jdata, file_name):\n",
        "  # create new json file for new_data\n",
        "  file = open(file_name, \"w\")\n",
        "  json_data = []\n",
        "\n",
        "  for line in tqdm(jdata):\n",
        "    tmp_dict = dict()\n",
        "    if len(line[3]) != 0:\n",
        "      for i, key in enumerate(data_keys):\n",
        "          tmp_dict[key] = line[i]\n",
        "    else:\n",
        "      continue\n",
        "    json_data.append(tmp_dict)\n",
        "\n",
        "  json.dump(json_data, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTBDmU31hIkQ",
        "outputId": "c23f2ab6-ee5e-41d0-f78c-4561066153e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 36916/36916 [00:00<00:00, 77575.67it/s]\n",
            "100%|██████████| 12306/12306 [00:00<00:00, 151022.04it/s]\n",
            "100%|██████████| 12306/12306 [00:00<00:00, 92658.27it/s]\n"
          ]
        }
      ],
      "source": [
        "create_json(new_train_data, \"HighCountVQA_train.json\")\n",
        "create_json(new_val_data, \"HighCountVQA_val.json\")\n",
        "create_json(new_test_data, \"HighCountVQA_test.json\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM34Pw/e8W862F8v6w1foK2",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}